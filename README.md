# ğŸ–¼ï¸ Image Caption Generator using Deep Learning

## ğŸ“Œ Overview
This project implements an **Image Caption Generator** that automatically generates meaningful natural language descriptions for images.  
It combines **Computer Vision** and **Natural Language Processing (NLP)** using a deep learningâ€“based **encoderâ€“decoder architecture**.

The model uses a pretrained **CNN (Xception)** to extract visual features from images and an **LSTM-based decoder** to generate captions word by word.

---

## ğŸš€ Features
- Generates human-like captions for input images
- Uses **pretrained Xception CNN** for robust image feature extraction
- Sequence-to-sequence caption generation using **LSTM**
- Custom **data generator** for memory-efficient training
- Supports **Greedy decoding** (Beam Search can be extended)
- Compatible with COCO dataset format
- Modular and extensible design

---

## ğŸ§  Model Architecture

### Encoder (Image Feature Extractor)
- Pretrained **Xception** model (ImageNet weights)
- Final classification layer removed
- Global Average Pooling â†’ 2048-dimensional feature vector
- Dense layer to reduce dimensionality

### Decoder (Caption Generator)
- Word embeddings for captions
- LSTM to capture linguistic context
- Image features and text features merged using element-wise addition
- Softmax layer predicts the next word in the sequence

**Inputs:**
- Image feature vector  
- Partial caption sequence
- <img width="970" height="647" alt="image" src="https://github.com/user-attachments/assets/e2c679fc-fffa-4573-a748-77c288f26c34" />
- A boy is riding a bicycle on the road.

**Output:**
- Next predicted word

---

## ğŸ“‚ Dataset
- **COCO (Common Objects in Context) Dataset**
- Each image has **multiple human-written captions**
- COCO API (`pycocotools`) used for loading images and annotations

Files used:
- `captions_train2017.json`
- `instances_train2017.json`
- COCO train & validation images

---

## ğŸ”„ Data Preprocessing

### Image Preprocessing
- Resize images to **299 Ã— 299**
- Normalize pixel values to range `[-1, 1]`
- Extract 2048-dim features using Xception

### Caption Preprocessing
- Convert text to lowercase
- Remove punctuation and special characters
- Replace hyphens with spaces
- Add `<start>` and `<end>` tokens
- Tokenize captions using Keras `Tokenizer`
- Pad sequences to maximum caption length

---

## âš™ï¸ Training Strategy
- Loss function: **Categorical Cross-Entropy**
- Optimizer: **Adam**
- Custom Python generator used to:
  - Reduce memory usage
  - Dynamically generate `(image, caption) â†’ next word` pairs
- Dropout layers added to reduce overfitting

---

## ğŸ§ª Inference Pipeline
1. Input image passed through Xception to extract features
2. Caption generation starts with `<start>` token
3. Model predicts next word iteratively
4. Stops when `<end>` token or max length is reached

---

## ğŸ“Š Evaluation
- Qualitative evaluation by visual inspection of generated captions
- BLEU score evaluation can be added for quantitative analysis
- Greedy decoding implemented (Beam Search supported)

---

## ğŸ› ï¸ Technologies Used
- Python
- TensorFlow / Keras
- Xception CNN
- LSTM
- NumPy
- NLTK
- Matplotlib
- COCO API (pycocotools)

---

## ğŸ“ Project Structure

```text
image-caption-generator/
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ image_caption_generator.ipynb
â”‚   â””â”€â”€ exploratory_analysis.ipynb
â”‚
â”œâ”€â”€ data/                     # Dataset directory (not tracked in Git)
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ captions.txt
â”‚
â”œâ”€â”€ models/                   # Saved models & checkpoints (ignored)
â”‚   â””â”€â”€ caption_model.h5
â”‚
â”œâ”€â”€ src/                      # Source code (optional refactor)
â”‚   â”œâ”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ feature_extraction.py
â”‚   â”œâ”€â”€ model.py
â”‚   â””â”€â”€ inference.py
â”‚
â”œâ”€â”€ outputs/
â”‚   â””â”€â”€ sample_predictions.png
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ LICENSE
```
---

## ğŸŒ Real-World Applications
- Assistive technology for visually impaired users
- Automatic alt-text generation for accessibility
- Image search and content indexing
- Social media photo tagging
- E-commerce product description generation
- Surveillance and security reporting

---

## ğŸ§  Challenges Faced & Learnings
- **Poor initial caption quality** â†’ improved via better preprocessing and CNN selection
- **Large dataset memory constraints** â†’ solved using data generators
- **Sequence alignment issues** â†’ resolved by careful input-output pairing
- Strong hands-on experience in **multi-modal deep learning**

---

## ğŸ”® Future Improvements
- Integrate **attention mechanism**
- Implement **beam search decoding**
- Explore **Transformer-based architectures**
- Add BLEU, METEOR, CIDEr evaluation
- Fine-tune CNN layers for domain-specific data

---

## ğŸ‘©â€ğŸ’» Author
**Swati Mittal**  
B.Tech Computer Science  
Deep Learning | Computer Vision | NLP  

---

## â­ Acknowledgements
- COCO Dataset
- TensorFlow & Keras community
- Research work on image captioning and encoderâ€“decoder models

